{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edf987c",
   "metadata": {},
   "source": [
    "# Podcast Studio – Jupyter Notebook Overview\n",
    "\n",
    "This Jupyter notebook implements an **end-to-end podcast generation pipeline**.  \n",
    "Given one or more **URLs**, it:\n",
    "\n",
    "1. Fetches and cleans text from web pages\n",
    "2. Generates a podcast script using OpenAI\n",
    "3. Converts the script to audio in chunks\n",
    "4. Merges the audio chunks into a single file\n",
    "5. Exposes the workflow through a **Gradio web interface**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdf8b2",
   "metadata": {},
   "source": [
    "## Step 1 – Setup & OpenAI API Connectivity Test\n",
    "\n",
    "This cell is a **sanity check** for the prototype.  \n",
    "Its goal is to confirm that the environment and OpenAI API connection are working **before** building the rest of the pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### What this step does\n",
    "\n",
    "- Loads environment variables from a `.env` file\n",
    "- Reads the OpenAI API key securely\n",
    "- Initializes the OpenAI client\n",
    "- Sends a minimal test prompt to the model\n",
    "- Prints the model’s response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "923e9272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def say_hello():\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",  # or another available model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Say hello to me in one short sentence.\"}\n",
    "        ]\n",
    "    )\n",
    "    # Get the text of the assistant's reply\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    hello_message = say_hello()\n",
    "    print(hello_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7857b475",
   "metadata": {},
   "source": [
    "## Step 2 – Web Article Fetching & Text Extraction\n",
    "\n",
    "This step is responsible for **turning web pages into clean, readable text** that can be used as input for the podcast script.  \n",
    "\n",
    "### What it does\n",
    "- Accepts a list of URLs pointing to online articles.\n",
    "- Downloads each web page and extracts the main textual content.\n",
    "- Removes HTML, scripts, navigation menus, ads, and other noise.\n",
    "- Prints a preview of the first part of the text to check that extraction worked correctly.\n",
    "- Includes error handling to ensure that if one URL fails, the process continues with the others.\n",
    "\n",
    "### Why this step matters\n",
    "- Provides the **raw material** for the podcast script generation.\n",
    "- Ensures the input to the AI is clean and readable.\n",
    "- Acts as a foundation for all subsequent steps in the pipeline (script generation, audio creation, and UI interaction).\n",
    "- Allows developers to validate and debug web content extraction quickly during prototype development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ef1ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Text content from: https://aeon.co/essays/how-the-fall-of-the-roman-empire-paved-the-road-to-modernity -----\n",
      "\n",
      "For an empire that collapsed more than 1,500 years ago, ancient Rome maintains a powerful presence. About 1 billion people speak languages derived from Latin; Roman law shapes modern norms; and Roman architecture has been widely imitated. Christianity, which the empire embraced in its sunset years, remains the world’s largest religion. Yet all these enduring influences pale against Rome’s most important legacy: its fall. Had its empire not unravelled, or had it been replaced by a similarly overpowering successor, the world wouldn’t have become modern.\n",
      "\n",
      "This isn’t the way that we ordinarily think about an event that has been lamented pretty much ever since it happened. In the late 18th century, in his monumental work The History of the Decline and Fall of the Roman Empire (1776-1788), the British historian Edward Gibbon called it ‘the greatest, perhaps, and most awful scene in the history of mankind’. Tankloads of ink have been expended on explaining it. Back in 1984, the German historian Alexander Demandt patiently compiled no fewer than 210 different reasons for Rome’s demise that had been put forward over time. And the flood of books and papers shows no sign of abating: most recently, disease and climate change have been pressed into service. Wouldn’t only a calamity of the first order warrant this kind of attention?\n",
      "\n",
      "It’s true that Rome’s collapse reverberated widely, at least in the western – mostly European – half of its empire. (A shrinking portion of the eastern half, later known as Byzantium, survived for another millennium.) Although some regions were harder hit than others, none escaped unscathed. Monumental structures fell into disrepair; previously thriving cities emptied out; Rome itself turned into a shadow of its former grand self, with shepherds tending their flocks among the ruins. Trade and coin use thinned out, and the art of writing retreated. Population numbers plummeted.\n",
      "\n",
      "But a few benefits were already being felt at the time. Roman power had f\n",
      "\n",
      "\n",
      "\n",
      "----- Text content from: https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml -----\n",
      "\n",
      "Dark ages In September 476 AD, the last Roman emperor of the west, Romulus Augustulus, was deposed by a Germanic prince called Odovacar, who had won control of the remnants of the Roman army of Italy. He then sent the western imperial regalia to Constantinople. The Roman empire in western Europe - a centralised superstate which had been in existence for 500 years - had ceased to exist, its single emperor replaced by upwards of a dozen kings and princes. The vast majority of these rulers, like Odovacar himself , were non-Roman in origin. Their power was based on the control of military forces which were the direct descendents of recent immigrants into the Roman world, whether Anglo-Saxons in Britain, Goths in southern Gaul and Spain, or Vandals in North Africa. The end of empire was a major event in human history. What difference did this political revolution make to real life in the former western Empire? For many 19th and earler 20th century commentators, the fall of Rome marked the death knell of education and literacy, sophisticated architecture, advanced economic interaction, and, not least, the rule of written law. The 'dark ages' which followed were dark not only because written sources were few and far between, but because life became nasty, brutish and short. Other commentators, who were more focused on the slavery and entrenched social hierarchies that were also part of the Roman world, didn't really disagree with these observations. But they saw the 'dark ages' as a more necessary evil - Rome had to fall to destroy large-scale slavery and make possible, eventually, a world which valued all human beings more equally. On either view, the end of empire was a major event in human history. Top\n",
      "\n",
      "Massive inequality The 1960s, however, were famously a time when all established certainties were challenged, and this applied to ancient history no less than to sexuality. The eastern half of the Roman empire not only survived the collapse of its western partner in the \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from newspaper import Article\n",
    "\n",
    "urls = [\n",
    "    \"https://aeon.co/essays/how-the-fall-of-the-roman-empire-paved-the-road-to-modernity\",\n",
    "    \"https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml\",\n",
    "]\n",
    "\n",
    "def fetch_and_print(urls):\n",
    "    for url in urls:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            print(f\"----- Text content from: {url} -----\\n\")\n",
    "            print(article.text[:2000])\n",
    "            print(\"\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33dea9",
   "metadata": {},
   "source": [
    "## Step 3 – End-to-End Podcast Script and Audio Generation (Prototype)\n",
    "\n",
    "This step combines **web content fetching, AI script writing, and text-to-speech generation** into a single prototype workflow. It demonstrates how the notebook transforms raw web articles into a playable podcast segment.\n",
    "\n",
    "---\n",
    "\n",
    "### What it does\n",
    "\n",
    "1. **Fetch articles**  \n",
    "   - Iterates through a list of URLs and downloads their content.  \n",
    "   - Extracts the main text from each web page.  \n",
    "   - Collects the articles in a structured format for later processing.  \n",
    "\n",
    "2. **Generate a podcast script**  \n",
    "   - Takes the extracted articles and concatenates them as sources.  \n",
    "   - Creates a detailed prompt for the OpenAI model, specifying:  \n",
    "     - Target audience (general curious listeners)  \n",
    "     - Tone (engaging, slightly narrative)  \n",
    "     - Episode structure (hook, context, key ideas, recap, reflective closing)  \n",
    "     - Optional host cues ([PAUSE], [MUSIC IN/OUT])  \n",
    "   - Sends the prompt to the OpenAI API to generate an original podcast script, **rephrasing ideas** rather than copying them.  \n",
    "\n",
    "3. **Convert the script to audio**  \n",
    "   - Uses a text-to-speech model to turn the script (or the first chunk of it) into an audio file.  \n",
    "   - Saves the generated audio as a `.mp3` file for playback.  \n",
    "\n",
    "4. **Prototype output**  \n",
    "   - Prints the generated script for review.  \n",
    "   - Produces a playable audio file representing a short podcast episode.  \n",
    "\n",
    "---\n",
    "\n",
    "### Why this step matters in the prototype\n",
    "\n",
    "- Shows a **complete proof-of-concept**: URL → Script → Audio.  \n",
    "- Validates integration between **web scraping**, **LLM-based script generation**, and **TTS**.  \n",
    "- Allows testing and iteration of prompt design, script structure, and voice generation.  \n",
    "- Forms the foundation for handling **multiple chunks**, more complex scripts, and eventual UI integration.  \n",
    "\n",
    "---\n",
    "\n",
    "This cell essentially demonstrates the **core functionality of the podcast studio** in a single, executable workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937e0a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== GENERATED PODCAST SCRIPT =====\n",
      "\n",
      "[MUSIC IN — a light, reflective tune fades in]\n",
      "\n",
      "Host: Imagine standing at the edge of a vast, once-mighty empire. The roads you’ve known fade into ruins, the coin you once used barely clinks in your pocket, and new rulers arrive with unfamiliar banners. It sounds like a catastrophe. But what if that very moment—the collapse—wasn’t the end of something, but the opening of something else entirely? A doorway through which a very different kind of world could begin to take shape. Welcome to Across the Ruins, where we ask how the fall of an empire helped spark a path to our modern world.\n",
      "\n",
      "[PAUSE, MUSIC FADES]\n",
      "\n",
      "Context and background\n",
      "\n",
      "Host: We’re talking about the fall of Rome in the western half of its empire—a transition that didn’t just rewrite maps, but rewired how power, money, and ideas circulated. By the late 5th century, central Rome’s grip loosened. Germanic kingdoms emerged on old soil, and the “Roman state” as a single, centralized machine gave way to a patchwork of kings, nobles, bishops, and growing towns that could bargain, compete, and chart their own courses. The East persisted for centuries longer, but the West entered a long, messy period that historians still debate: was it a cataclysm, or a transformation that dried up a certain old way of life only to let something new and unpredictable grow?\n",
      "\n",
      "Two quick milestones help frame this story. First, the logical end of a unified empire didn’t erase the weight of Roman institutions overnight. Second, with taxes, armies, and centralized authority thinning out, a new social landscape formed: councils, guilds, cities, and universities began to run as self-governing networks, often by negotiation rather than decree. This was not chaos for its own sake. It was a different kind of order—one built on bargaining, competition, and the idea that multiple centers of influence could shape the future.\n",
      "\n",
      "Three to five key ideas emerge when we look at the long arc from that collapse to modernity.\n",
      "\n",
      "Idea 1: Fragmentation as a driver of experimentation\n",
      "\n",
      "Host: The western world did not simply fall apart; it diversified. Once you don’t have one ruler calling all the shots from a single capital, you get many experiments in governance. Parliaments, that bustling mix of nobles, clergy, merchants, and townspeople, grew out of this multiplicity. Charters granted to cities, guilds that set the rules of trade, even universities that governed themselves—these arrangements created spaces where novel ideas could be tested away from a single royal will. In other words, disunity created room for different ways of living together, and the competition among these micro-polities kept innovation alive.\n",
      "\n",
      "Idea 2: The rise of a commercially minded, decentralized Europe\n",
      "\n",
      "Host: A big shift was the rise of merchants, craftspeople, and cities as economic engines. The old imperial model—one vast, centralized tax base supporting one big army—wasn’t easy to sustain once power fractured. In the absence of a single, all-encompassing system, smaller states and cities learned to cooperate, lend to one another, and protect their own interests. This environment helped seed a dynamic where commerce, finance, and invention could flourish side by side. It also meant the state’s power was exercised differently: not only by kings, but by councils, consuls, and city magistrates who could secure the purse and set the rules.\n",
      "\n",
      "Idea 3: Safe spaces for inquiry amid competing claims\n",
      "\n",
      "Host: Europe’s fragmentation mattered for knowledge too. If you were a thinker, a tinkerer, or a physician whose ideas unsettled orthodoxy, the landscape offered more refuge than a single, all-powerful regime did. Different religious and political groups clashed, yes, but they also created pockets where new schools of thought could survive and be tested. Refugees—think Luther, Calvin, and other scholars who moved between cities and courts—carried with them new practices, new questions, and new permissions to challenge tradition. Out of this crucible, a more empirical approach to knowledge began to take hold: ideas had to withstand open critique, not just the edict of a single ruler.\n",
      "\n",
      "Idea 4: The long-range costs and benefits of empire vs. fragmentation\n",
      "\n",
      "Host: It’s tempting to romanticize the “order” of empire, but the upside of Rome’s model came with heavy costs—top-down control, limited incentives for broad participation, and the tax-supported machine that could crush dissent when necessary. The alternative, as Europe gradually learned to live with, was not chaos but a shape-shifting system: competitive, negotiated, and open to reform. The result wasn’t automatic perfection, but a structural setup in which people could push for change, experiment with finance and law, and build civil society in ways that remained adaptable to new challenges.\n",
      "\n",
      "Idea 5: A global ripple that wasn’t inevitable\n",
      "\n",
      "Host: The story isn’t just about Europe. Across the globe, other great imperial systems rose and fell at their own tempos. China, for instance, sustained vast unity for long periods, while Europe, after Rome, moved toward a different kind of power—one rooted in pluralism, trade networks, and a culture that valued debate and new methods. When Europe later spread its models across oceans, the world felt the price and the payoff: wealth and inequality on an unprecedented scale, and a set of technologies and institutions that reshaped nearly every corner of the planet. The fall of Rome didn’t cause modernity by itself, but it created a laboratory where a new order could emerge—turbulent, contested, and faster-changing than the empire that had gone before.\n",
      "\n",
      "A brief recap\n",
      "\n",
      "Host: In short, Rome’s fall didn’t mean the end of civilization. It marked the start of a long, uneven journey where fragmentation allowed diverse centers of power to innovate, bargain, and culture-shape society. Out of dispersed authorities and competing interests came new kinds of governance, new scientific and technical pathways, and new economic arrangements. The price tag included frequent conflict, inequality, and at times brutal colonial expansion. Yet without the disintegration of that ancient empire, the modern world—with its universities, markets, and representative politics—most likely would never have unfolded in the way it did.\n",
      "\n",
      "Reflective closing question\n",
      "\n",
      "Host: So here’s a thought to carry with you: if progress depends on disunion as a catalyst, what does that imply for the way we handle discord today? Is our current era of fragmentation a hindrance or a hidden engine for innovation? And as we navigate our own long twilight between old orders and new ones, what kinds of spaces—what kinds of bargaining—and what kinds of freedoms do we need to build a society that can face an uncertain future?\n",
      "\n",
      "[PAUSE, MUSIC IN — a gentle lift]\n",
      "\n",
      "Host: Thanks for listening to Across the Ruins. If you enjoyed this look at how the fall of a colossal empire helped spark modern life, tell a friend about the show. We’ll be back with more stories from the long arc of human history, where ruins whisper about what comes next.\n",
      "\n",
      "[MUSIC OUT]\n",
      "Audio file created: podcast_episode.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from newspaper import Article\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "urls = [\n",
    "    \"https://aeon.co/essays/how-the-fall-of-the-roman-empire-paved-the-road-to-modernity\",\n",
    "    \"https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml\",\n",
    "]\n",
    "\n",
    "def fetch_articles(urls):\n",
    "    articles = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "\n",
    "            articles.append({\n",
    "                \"url\": url,\n",
    "                \"text\": article.text\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "\n",
    "    return articles\n",
    "\n",
    "\n",
    "def generate_podcast_script(articles):\n",
    "    sources_text = \"\"\n",
    "    for i, a in enumerate(articles, start=1):\n",
    "        sources_text += f\"\\nSOURCE {i} ({a['url']}):\\n{a['text']}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a podcast scriptwriter.\n",
    "\n",
    "Task:\n",
    "Using the sources below, write an ORIGINAL podcast script suitable for a\n",
    "5–10 minute episode.\n",
    "\n",
    "Guidelines:\n",
    "- Target audience: curious general listeners\n",
    "- Tone: clear, engaging, slightly narrative\n",
    "- Do NOT copy sentences or paragraphs from the sources\n",
    "- Rephrase ideas in your own words\n",
    "- Structure:\n",
    "  1. Hook (30–45 seconds)\n",
    "  2. Context and background\n",
    "  3. 3–5 key ideas with explanations\n",
    "  4. Short recap\n",
    "  5. Reflective closing question\n",
    "\n",
    "Optional:\n",
    "- Light host cues like [PAUSE], [MUSIC IN], [MUSIC OUT]\n",
    "\n",
    "Sources:\n",
    "{sources_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You write engaging podcast scripts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    articles = fetch_articles(urls)\n",
    "    script = generate_podcast_script(articles)\n",
    "\n",
    "    print(\"\\n===== GENERATED PODCAST SCRIPT =====\\n\")\n",
    "    print(script)\n",
    "\n",
    "    speech = client.audio.speech.create(\n",
    "    model=\"tts-1\",\n",
    "    voice=\"alloy\",\n",
    "    input=script[:4000]\n",
    ")\n",
    "\n",
    "    output_file = \"podcast_episode.mp3\"\n",
    "\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "\n",
    "    print(f\"Audio file created: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db185efe",
   "metadata": {},
   "source": [
    "## Step 4 – Full Prototype Pipeline with Chunking, TTS, and Audio Concatenation\n",
    "\n",
    "This cell represents the **an almost complete version of the prototype**, combining all prior steps and adding robust handling for long scripts, multiple audio chunks, and final podcast assembly.\n",
    "\n",
    "---\n",
    "\n",
    "### What it does\n",
    "\n",
    "1. **Configuration & Setup**\n",
    "   - Loads environment variables and initializes the OpenAI client.\n",
    "   - Defines input URLs, output directories, TTS model/voice, and chunk size limits.\n",
    "   - Prepares folders for storing temporary chunk files and the final episode.\n",
    "\n",
    "2. **Web Article Fetching**\n",
    "   - Downloads and parses each URL into clean text.\n",
    "   - Stores articles in a structured format for script generation.\n",
    "   - Includes error handling to skip problematic URLs without halting the pipeline.\n",
    "\n",
    "3. **Podcast Script Generation**\n",
    "   - Aggregates all fetched articles into a prompt for the LLM.\n",
    "   - Defines a detailed podcast structure, tone, and narrative style:\n",
    "     - Hook, context, 3–5 key ideas, recap, reflective closing.\n",
    "     - Emphasizes storytelling and lessons from history.\n",
    "   - Sends the prompt to the OpenAI model to produce an original script.\n",
    "\n",
    "4. **Chunking the Script**\n",
    "   - Splits the script into manageable segments for TTS.\n",
    "   - Ensures chunks do not exceed TTS model limits.\n",
    "   - Respects paragraph and sentence boundaries when possible.\n",
    "   - Produces a list of text chunks ready for audio conversion.\n",
    "\n",
    "5. **Text-to-Speech (TTS)**\n",
    "   - Converts each chunk into an individual MP3 file.\n",
    "   - Supports multiple voices or TTS models.\n",
    "   - Saves each chunk to a dedicated output directory.\n",
    "\n",
    "6. **Audio Concatenation**\n",
    "   - Combines all chunked MP3 files into a single episode.\n",
    "   - Uses **ffmpeg** if available for robust and fast concatenation.\n",
    "   - Falls back to **pydub** if ffmpeg is not installed.\n",
    "   - Ensures the final audio file is continuous and playable.\n",
    "\n",
    "7. **Prototype Output**\n",
    "   - Prints a preview of the generated script.\n",
    "   - Shows the number of chunks and progress during TTS generation.\n",
    "   - Confirms the path of the final audio file once completed.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this step matters in the prototype\n",
    "\n",
    "- Demonstrates a **production-ready workflow** from URLs to a finished podcast episode.\n",
    "- Handles **long scripts** and ensures TTS limitations do not break the pipeline.\n",
    "- Separates concerns:\n",
    "  - Fetching articles\n",
    "  - Script generation\n",
    "  - Chunking\n",
    "  - Audio creation\n",
    "  - Final assembly\n",
    "- Provides a clear structure for moving from **notebook prototyping** to **modular Python scripts**.\n",
    "\n",
    "This step essentially represents the **core engine of the AI podcast studio**, capable of generating full episodes from multiple sources in an automated, reproducible way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a519c3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== GENERATED PODCAST SCRIPT (preview) =====\n",
      "\n",
      "Hook\n",
      "\n",
      "SFX: a faint wind across stone, then the creak of a timber door. A distant hammer on an anvil, markets waking, horses neighing.\n",
      "\n",
      "NARRATOR: Imagine a city built on stone and speech: Rome at its zenith, a tapestry of law, roads, temples, and a language that would echo for centuries. It’s not just a museum showpiece. It’s a living machine of power, culture, and engineering that once stitched a world together. And then—dramatically, almost overnight—the machine falters. Armies shift, money vanishes from the mint, and a city that once sent legions across continents becomes a shadow of its former self. What went wrong? And more hauntingly: if a superpower can fall, what patterns in our own world might be repeating themselves right now?\n",
      "\n",
      "Rome was not merely a city or a collection of rulers. It was one of humanity’s greatest experiments in scale, law, and unity. Its fall didn’t just mark the end of an empire; it seeded a long, uneven ascent into what we’d later call modernity. If you stand back and listen, history keeps telling a familiar story: centralized power struggles to keep its grip, change arrives from the edges, and society reconfigures itself in surprising ways. Could the lessons of ancient Rome help us understand the challenges of our own time?\n",
      "\n",
      "Context and background\n",
      "\n",
      "NARRATOR: At its peak, Rome stretched from Britain to Mesopotamia, the map crowded with provinces, legions, and a vast network of roads that stitched far-flung lands together. Its strength wasn’t only in soldiers or walls, but in a system—an immense bureaucracy, a legal framework, and a common coin—that kept commerce moving, laws enforceable, and cultures interlinked. Latin logistics and Roman law still echo in our courts and languages; Christian faith—an idea once controversial—evolved under Roman auspices to become a global religion. The empire’s unity didn’t just last; it endured for centuries through both organization and technology, including monumental architecture and engineering that defined an era.\n",
      "\n",
      "But every empire has a lifespan, and Rome’s was no exception. In the late centuries of the West, a cascade of pressures began to bite harder: pressure from frontiers as groups like Goths and Vandals pressed in; pressure from within as expensive wars drained treasuries; and pressure from governance itself as the empire grew too large to manage with a single, all-powerful center. By 476 CE, the last western emperor, Romulus Augustulus, was deposed by Odovacar, a Germanic chieftain who controlled the remnants of Italy’s army. The West fractured into rival kingdoms led by non-Roman elites; the East, by contrast, persisted for another thousand years as Byzantium, preserving many Roman institutions even as the world around it shifted.\n",
      "\n",
      "Yet the fall was not a single moment so much as a long transformation: a two-stage process of migration and consolidation where central taxation and imperial reach withered as local power rose. The center could no longer command the wealth it needed to sustain its armies, and the rulers who replaced it often relied on different forms of authority—local warlords, landed elites, and increasingly autonomous cities. The result was a Europe that looked nothing like the Rome that had built it, but would give rise to something new: a patchwork of kingdoms, a flowering of towns and guilds, and ultimately the groundwork for modern states.\n",
      "\n",
      "3–5 key ideas (the through-line of Rome’s fall, told as a story)\n",
      "\n",
      "Idea 1: The burden and fragility of a vast empire\n",
      "NARRATOR: Rome’s size was both its crown and its Achilles heel. It could mobilize mighty forces, but keeping such a machine running required steady revenues, a reliable tax system, and a centralized administration that could purr like a well-oiled engine. When migrants and invaders disrupted the traditional tax base, the central state could no longer fund its legions or maintain essential infrastructure. The very tools that kept order—roads, aqueducts, large-scale transport—began to crumble. As the central power weakened, provincial life shifted toward local solutions, which, over time, diluted imperial coherence and accelerated fragmentation.\n",
      "\n",
      "Idea 2: Migrations, frontiers, and the price of central control\n",
      "NARRATOR: The late Roman world became a mosaic of newcomers and local elites. It wasn’t simply a collapse; it was a transformation. Across Gaul, Spain, and Italy, landowners faced a stark choice: work with the new migrants and the new rulers, or resist and risk losing their holdings. This pressure reshaped societies from the ground up. In the short term, rulers found their power withered; in the longer run, new kingdoms rose on the backs of soldiers who hailed from the very groups that had once been outsiders. The central state slide from a mighty imperial machine to a constellation of local powers reshaped not only borders but the habits of governance, taxation, and loyalty.\n",
      "\n",
      "Idea 3: The surprising value of fragmentation for long-term progress\n",
      "NARRATOR: Here’s a counterintuitive twist from history. The long, messy aftermath of Rome’s collapse created a Europe that was unusually good at changing its ways: pluralism, bargaining, and a web of semi-autonomous cities and kingdoms. While centralized states once offered broad security, they often concentrated power and stifled new ideas. After Rome, Europe learned to mix governance—parliaments, charters, guilds, and universities—so that many voices could push for change. This “permission structure,” as some historians put it, allowed science, commerce, and reform to push forward in a way that an overbearing empire might have strangled. The engine of modernity—trade, knowledge, and innovation—found room to breathe precisely because no single ruler could dictate every detail of life.\n",
      "\n",
      "Idea 4: Knowledge, innovation, and the edge of conflict\n",
      "NARRATOR: The story isn’t just about politics; it’s about culture and ideas. In a world of competing centers of power, dissent could flourish when safeguarded by multiple authorities. Think of the scholars, artisans, and merchants who fled persecution or censorship and brought with them new ways of thinking. In this environment, evidence and experiment mattered more than dogma. That openness helped lay the foundations for scientific method, new technologies, and the kind of economic growth that later fed a global market. Europe’s patchwork structure—with its cities, universities, and protected spaces for inquiry—made room for the kind of disruptive thinking that would later spark Renaissance breakthroughs and the rise of modern capitalism.\n",
      "\n",
      "Idea 5: The lasting lesson—and the caution\n",
      "NARRATOR: Rome’s fall isn’t simply a tragedy; it’s a prompt to ask big questions about stability, growth, and how societies change. A centralized empire can deliver order and scale, but it can also choke innovation and compress the political imagination. A fragmented, negotiation-rich landscape can fuel progress, yet it can invite volatility and inequality. The arc of Rome’s decline, and Europe’s subsequent transformation, shows that durable progress often comes from balancing unity with room for local initiative, from protecting open inquiry while maintaining shared rules, and from learning to adapt when resources, borders, and loyalties shift.\n",
      "\n",
      "Short recap\n",
      "\n",
      "NARRATOR: In brief:\n",
      "- Rome’s peak was a triumph of scale, law, and networks, backed by a central state that could mobilize vast resources.\n",
      "- The fall arose from a combination of external pressure (frontier migrations) and internal strain (tax bases shrinking, governance frayed).\n",
      "- The immediate aftermath fractured the West into many kingdoms, while the East persisted as Byzantium for centuries.\n",
      "- The long-term payoff of later Europe lay in a plural, bargaining-minded political culture that protected space for merchants, cities, and scholars to innovate.\n",
      "- The lesson for today is clear: stability and innovation aren’t enemies; they thrive when power is exercised with enough flexibility to adapt to changing circumstances.\n",
      "\n",
      "Reflective closing question\n",
      "\n",
      "NARRATOR: If history teaches us anything, it’s that the most enduring paths forward often begin with questions, not certainties: What if our modern states could combine the scale and security of centralized power with the diversity and resilience that come from pluralism? How might our own world benefit from a design that preserves both the rule of law and the space for new ideas to challenge it? Could the lessons of ancient Rome—its rise, its fall, and the centuries that followed—help us think more clearly about our most urgent challenges today?\n",
      "\n",
      "Closing credits and sign-off\n",
      "\n",
      "NARRATOR: This episode was a journey through the fall of the Roman Empire and the long, winding road to modern Europe. If you enjoyed it, share it with someone who loves big histories and fresh perspectives. I’m [Your Name], and I’ll be back with more stories from the past that still speak to our present. Until then, keep listening for the patterns that history keeps repeating, and never stop asking: what can we learn from yesterday to better navigate tomorrow?\n",
      "\n",
      "Notes for production (optional)\n",
      "- Sound cues can punctuate transitions: the clink of coins when discussing funding; the roar of a crowd for moments of imperial power; distant drums and marching feet for migration and conflict; a soft scholarly hum when discussing ideas and pluralism.\n",
      "- Pacing should dip into reflective, slower tones when explaining how the center collapsed and rose anew in Europe, then lift into a brighter tempo when describing the rise of cities, guilds, and universities.\n",
      "- If you want to weave in direct aural clips, consider brief, non-intrusive excerpts from lectures or readings about Hadrian’s Wall or the Hagia Sophia to anchor listeners in each era.\n",
      "\n",
      "This script is designed to be engaging, informative, and thought-provoking for curious listeners, while drawing on the main points and interpretations from the provided sources. It emphasizes clear storytelling, a cinematic tone, and the practical takeaways that connect Rome’s fall to today’s world.\n",
      "...\n",
      "\n",
      "\n",
      "Chunked script into 4 parts (<= 3500 chars each).\n",
      "Generating audio for chunk 1/4 -> podcast_output/chunks/chunk_01.mp3\n",
      "Generating audio for chunk 2/4 -> podcast_output/chunks/chunk_02.mp3\n",
      "Generating audio for chunk 3/4 -> podcast_output/chunks/chunk_03.mp3\n",
      "Generating audio for chunk 4/4 -> podcast_output/chunks/chunk_04.mp3\n",
      "\n",
      "Combining chunks into final audio...\n",
      "\n",
      "Done. Final audio file created: podcast_output/podcast_episode_final.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from newspaper import Article\n",
    "from openai import OpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "urls = [\n",
    "    \"https://aeon.co/essays/how-the-fall-of-the-roman-empire-paved-the-road-to-modernity\",\n",
    "    \"https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml\",\n",
    "    \"https://www.khanacademy.org/humanities/whp-origins/x23c41635548726c4:regional-webs/x23c41635548726c4:why-do-empires-collapse-5-2/a/article-the-fall-of-rome\"\n",
    "]\n",
    "\n",
    "OUTPUT_DIR = Path(\"podcast_output\")\n",
    "CHUNKS_DIR = OUTPUT_DIR / \"chunks\"\n",
    "FINAL_AUDIO = OUTPUT_DIR / \"podcast_episode_final.mp3\"\n",
    "\n",
    "TTS_MODEL = \"tts-1\"\n",
    "TTS_VOICE = \"onyx\"\n",
    "\n",
    "# Keep headroom for TTS limits\n",
    "MAX_CHARS_PER_CHUNK = 3500\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch + Script generation\n",
    "# -----------------------------\n",
    "def fetch_articles(urls):\n",
    "    articles = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            articles.append({\"url\": url, \"text\": article.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "    return articles\n",
    "\n",
    "\n",
    "def generate_podcast_script(articles):\n",
    "    sources_text = \"\"\n",
    "    for i, a in enumerate(articles, start=1):\n",
    "        sources_text += f\"\\nSOURCE {i} ({a['url']}):\\n{a['text']}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "\n",
    "You are a podcast scriptwriter and narrator.\n",
    "Task: Using the sources below, write an ORIGINAL podcast script about the fall of the Roman Empire, suitable for a 8–10 minute episode.\n",
    "Guidelines for the script:\n",
    "Audience: curious general listeners\n",
    "Tone: clear, engaging, slightly narrative, cinematic\n",
    "Do NOT copy sentences or paragraphs; rephrase ideas in your own words\n",
    "Highlight lessons from history – show how events from the past may provide insights into today\n",
    "Structure:\n",
    "Hook (30–45 seconds) – grab attention with a dramatic scene and the idea that history repeats itself; for example:\n",
    "Introduce Rome as one of the most advanced and significant civilizations ever\n",
    "Emphasize that understanding its decline can give clues about patterns in our world today\n",
    "Pose a reflective question to the listener: “Could the lessons of ancient Rome help us understand the challenges of our own time?”\n",
    "Context and background – explain the empire’s peak, structure, significance, and key players\n",
    "3–5 key ideas – focus on the main causes and consequences of Rome’s fall, explained clearly and with storytelling flair\n",
    "Short recap – summarize the main points\n",
    "Reflective closing question – tie back to learning from history and its relevance today\n",
    "Narration style:\n",
    "Speak in a natural, clear, and engaging voice\n",
    "Use expressive tone, pacing, and pauses to emphasize dramatic moments\n",
    "Ensure the listener can follow the story easily while staying engaged\n",
    "End result: A script ready for a podcast episode that explains the fall of the Roman Empire, its key players, and the lessons we can learn today.\n",
    "\n",
    "Sources:\n",
    "{sources_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You write engaging podcast scripts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Chunking\n",
    "# -----------------------------\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_chars: int = MAX_CHARS_PER_CHUNK) -> list[str]:\n",
    "    \"\"\"\n",
    "    Chunk by paragraphs, then by sentences if needed.\n",
    "    Avoids cutting mid-sentence when possible.\n",
    "    Hard-slices only as a last resort.\n",
    "    \"\"\"\n",
    "    text = normalize_whitespace(text)\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "\n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current\n",
    "        if current.strip():\n",
    "            chunks.append(current.strip())\n",
    "        current = \"\"\n",
    "\n",
    "    sentence_split = re.compile(r\"(?<=[.!?])\\s+\")\n",
    "\n",
    "    for p in paragraphs:\n",
    "        parts = [p]\n",
    "        if len(p) > max_chars:\n",
    "            parts = sentence_split.split(p)\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if not part:\n",
    "                continue\n",
    "\n",
    "            candidate = part if not current else current + \"\\n\\n\" + part\n",
    "\n",
    "            if len(candidate) <= max_chars:\n",
    "                current = candidate\n",
    "            else:\n",
    "                flush()\n",
    "\n",
    "                if len(part) > max_chars:\n",
    "                    for i in range(0, len(part), max_chars):\n",
    "                        piece = part[i : i + max_chars].strip()\n",
    "                        if piece:\n",
    "                            chunks.append(piece)\n",
    "                else:\n",
    "                    current = part\n",
    "\n",
    "    flush()\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TTS\n",
    "# -----------------------------\n",
    "def tts_to_mp3(text: str, out_path: Path):\n",
    "    speech = client.audio.speech.create(\n",
    "        model=TTS_MODEL,\n",
    "        voice=TTS_VOICE,\n",
    "        input=text,\n",
    "    )\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Audio concat (absolute paths)\n",
    "# -----------------------------\n",
    "def ffmpeg_available() -> bool:\n",
    "    return shutil.which(\"ffmpeg\") is not None\n",
    "\n",
    "\n",
    "def _ffmpeg_concat_escape(path: Path) -> str:\n",
    "    # concat demuxer lines are: file '...'\n",
    "    # use absolute posix path + escape single quotes\n",
    "    p = path.resolve().as_posix()\n",
    "    return p.replace(\"'\", r\"'\\''\")\n",
    "\n",
    "\n",
    "def concat_mp3_ffmpeg(mp3_files: list[Path], out_file: Path):\n",
    "    \"\"\"\n",
    "    Robust concat:\n",
    "      1) Try stream-copy concat (fast, may fail for MP3 chunks).\n",
    "      2) Retry with re-encode (reliable).\n",
    "    Uses absolute paths in concat_list to avoid path duplication issues.\n",
    "    \"\"\"\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    list_file = out_file.parent / \"concat_list.txt\"\n",
    "\n",
    "    # Ensure all files exist before calling ffmpeg\n",
    "    missing = [p for p in mp3_files if not p.exists()]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Missing chunk files: {missing}\")\n",
    "\n",
    "    with open(list_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in mp3_files:\n",
    "            f.write(f\"file '{_ffmpeg_concat_escape(p)}'\\n\")\n",
    "\n",
    "    def run(cmd: list[str]):\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if res.returncode != 0:\n",
    "            raise RuntimeError(\n",
    "                \"ffmpeg concat failed.\\n\"\n",
    "                f\"CMD: {' '.join(cmd)}\\n\\n\"\n",
    "                f\"STDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}\"\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    # 1) Stream-copy\n",
    "    try:\n",
    "        run([\n",
    "            \"ffmpeg\", \"-y\",\n",
    "            \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "            \"-i\", str(list_file),\n",
    "            \"-c\", \"copy\",\n",
    "            str(out_file),\n",
    "        ])\n",
    "        return\n",
    "    except RuntimeError as e:\n",
    "        print(str(e))\n",
    "        print(\"\\nRetrying with re-encode (more reliable)...\\n\")\n",
    "\n",
    "    # 2) Re-encode\n",
    "    run([\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "        \"-i\", str(list_file),\n",
    "        \"-vn\",\n",
    "        \"-c:a\", \"libmp3lame\",\n",
    "        \"-q:a\", \"2\",\n",
    "        \"-ar\", \"44100\",\n",
    "        \"-ac\", \"2\",\n",
    "        str(out_file),\n",
    "    ])\n",
    "\n",
    "\n",
    "def concat_mp3_pydub(mp3_files: list[Path], out_file: Path):\n",
    "    from pydub import AudioSegment  # pip install pydub\n",
    "\n",
    "    combined = AudioSegment.empty()\n",
    "    for p in mp3_files:\n",
    "        combined += AudioSegment.from_file(p, format=\"mp3\")\n",
    "\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined.export(out_file, format=\"mp3\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    CHUNKS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    articles = fetch_articles(urls)\n",
    "    if not articles:\n",
    "        raise RuntimeError(\"No articles fetched. Check URLs / connectivity.\")\n",
    "\n",
    "    script = generate_podcast_script(articles)\n",
    "\n",
    "    print(\"\\n===== GENERATED PODCAST SCRIPT (preview) =====\\n\")\n",
    "    print(script + (\"\\n...\\n\" if len(script) > 2000 else \"\"))\n",
    "\n",
    "    chunks = chunk_text(script, max_chars=MAX_CHARS_PER_CHUNK)\n",
    "    print(f\"\\nChunked script into {len(chunks)} parts (<= {MAX_CHARS_PER_CHUNK} chars each).\")\n",
    "\n",
    "\n",
    "    mp3_files = []\n",
    "    for idx, chunk in enumerate(chunks, start=1):\n",
    "        mp3_path = CHUNKS_DIR / f\"chunk_{idx:02d}.mp3\"\n",
    "        print(f\"Generating audio for chunk {idx}/{len(chunks)} -> {mp3_path}\")\n",
    "        tts_to_mp3(chunk, mp3_path)\n",
    "        mp3_files.append(mp3_path)\n",
    "\n",
    "    print(\"\\nCombining chunks into final audio...\")\n",
    "\n",
    "    if ffmpeg_available():\n",
    "        concat_mp3_ffmpeg(mp3_files, FINAL_AUDIO)\n",
    "    else:\n",
    "        print(\"ffmpeg not found in PATH. Trying pydub fallback...\")\n",
    "        concat_mp3_pydub(mp3_files, FINAL_AUDIO)\n",
    "\n",
    "    print(f\"\\nDone. Final audio file created: {FINAL_AUDIO.as_posix()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d628ce",
   "metadata": {},
   "source": [
    "## Step 5 – Two-Voice Podcast Experiment\n",
    "\n",
    "This cell introduces a **proof-of-concept for multi-voice AI podcasts**, where two “speakers” (host and cohost) speak in turn. It demonstrates how to:\n",
    "\n",
    "- Parse a dialogue script with multiple speakers\n",
    "- Generate separate TTS audio segments per speaker\n",
    "- Insert short pauses for natural pacing\n",
    "- Concatenate all segments into a final podcast file\n",
    "\n",
    "---\n",
    "\n",
    "### What it does\n",
    "\n",
    "1. **Configuration & Setup**\n",
    "   - Initializes the OpenAI client and loads environment variables.\n",
    "   - Defines TTS model, voices for host and cohost, output directories, and pause duration between turns.\n",
    "   - Prepares folders for temporary segment files and the final audio.\n",
    "\n",
    "2. **Short Test Script**\n",
    "   - A simple dialogue script with `[HOST]` and `[COHOST]` tags.\n",
    "   - Serves as a prototype to test multi-voice rendering and segment handling.\n",
    "\n",
    "3. **Dialogue Parsing**\n",
    "   - Splits the script into structured speaker turns.\n",
    "   - Each turn contains the speaker identity and the corresponding text.\n",
    "   - Ensures that text for each speaker is clearly separated for TTS generation.\n",
    "\n",
    "4. **TTS Segment Generation**\n",
    "   - Converts each speaker turn into a separate MP3 file using the specified voice.\n",
    "   - Saves segments in a dedicated directory.\n",
    "   - Inserts silent audio segments to create natural pauses between turns.\n",
    "\n",
    "5. **Audio Concatenation**\n",
    "   - Combines all speaker segments and pauses into a single, continuous MP3.\n",
    "   - Uses `ffmpeg` to robustly handle concatenation and re-encoding.\n",
    "   - Ensures timing, audio quality, and speaker order are preserved.\n",
    "\n",
    "6. **Prototype Output**\n",
    "   - Prints progress for each segment as it is generated.\n",
    "   - Produces a final multi-voice MP3 file for listening.\n",
    "   - Validates that multiple voices and pacing can work in a single episode.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this step matters in the prototype\n",
    "\n",
    "- Demonstrates **multi-voice AI capabilities**, moving beyond single-voice narration.\n",
    "- Provides a template for **host/cohost dialogue** in podcasts.\n",
    "- Allows testing of **timing, pacing, and natural transitions**.\n",
    "- Forms the foundation for future features like:\n",
    "  - Multiple guest voices\n",
    "  - Dynamic speaker assignments\n",
    "  - More complex conversational scripts\n",
    "\n",
    "This step extends the prototype from linear, single-voice narration to **interactive, multi-speaker episodes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cbe211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 segments with two voices using model=gpt-4o-mini-tts...\n",
      "  01. HOST -> seg_01_host.mp3\n",
      "  02. COHOST -> seg_02_cohost.mp3\n",
      "  03. HOST -> seg_03_host.mp3\n",
      "  04. COHOST -> seg_04_cohost.mp3\n",
      "  05. HOST -> seg_05_host.mp3\n",
      "Concatenating into final audio...\n",
      "Done: tts_two_voice_test/two_voice_test_final.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# TTS model: set this to what your account supports.\n",
    "# Try: \"gpt-4o-mini-tts\" or fallback to \"tts-1\"\n",
    "TTS_MODEL = \"gpt-4o-mini-tts\"\n",
    "HOST_VOICE = \"alloy\"\n",
    "COHOST_VOICE = \"cedar\"\n",
    "\n",
    "OUTPUT_DIR = Path(\"tts_two_voice_test\")\n",
    "SEG_DIR = OUTPUT_DIR / \"segments\"\n",
    "FINAL_AUDIO = OUTPUT_DIR / \"two_voice_test_final.mp3\"\n",
    "\n",
    "PAUSE_MS_BETWEEN_TURNS = 450  # pacing pause\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Short test script (two speakers)\n",
    "# -----------------------------\n",
    "TEST_SCRIPT = \"\"\"\n",
    "[HOST]\n",
    "Hey! Welcome back. Quick experiment: can AI do a natural two-voice podcast?\n",
    "\n",
    "[COHOST]\n",
    "Let’s find out. I’ll ask questions, you keep us on track.\n",
    "\n",
    "[HOST]\n",
    "Deal. First topic: why we should keep sentences short for text to speech.\n",
    "\n",
    "[COHOST]\n",
    "Because long sentences sound like someone reading an essay out loud.\n",
    "\n",
    "[HOST]\n",
    "Exactly. Okay, let’s render this and stitch it together.\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def ffmpeg_available() -> bool:\n",
    "    return shutil.which(\"ffmpeg\") is not None\n",
    "\n",
    "\n",
    "def run(cmd: list[str]) -> None:\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if res.returncode != 0:\n",
    "        raise RuntimeError(\n",
    "            \"Command failed.\\n\"\n",
    "            f\"CMD: {' '.join(cmd)}\\n\\n\"\n",
    "            f\"STDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def parse_dialogue(script: str):\n",
    "    \"\"\"\n",
    "    Parses blocks like:\n",
    "      [HOST]\n",
    "      text...\n",
    "      [COHOST]\n",
    "      text...\n",
    "    Returns: list of {\"speaker\": \"...\", \"text\": \"...\"}\n",
    "    \"\"\"\n",
    "    lines = [ln.rstrip() for ln in script.splitlines()]\n",
    "    blocks = []\n",
    "    current_speaker = None\n",
    "    current_text = []\n",
    "\n",
    "    tag_re = re.compile(r\"^\\[(HOST|COHOST)\\]\\s*$\")\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current_speaker, current_text\n",
    "        if current_speaker and any(t.strip() for t in current_text):\n",
    "            blocks.append(\n",
    "                {\"speaker\": current_speaker, \"text\": \"\\n\".join(current_text).strip()}\n",
    "            )\n",
    "        current_text = []\n",
    "\n",
    "    for ln in lines:\n",
    "        m = tag_re.match(ln.strip())\n",
    "        if m:\n",
    "            flush()\n",
    "            current_speaker = m.group(1)\n",
    "        else:\n",
    "            if current_speaker is not None:\n",
    "                current_text.append(ln)\n",
    "\n",
    "    flush()\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def tts_segment(text: str, voice: str, out_path: Path):\n",
    "    \"\"\"\n",
    "    Generates one MP3 segment for a single speaker turn.\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    speech = client.audio.speech.create(\n",
    "        model=TTS_MODEL,\n",
    "        voice=voice,\n",
    "        input=text,\n",
    "    )\n",
    "\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "\n",
    "\n",
    "def make_silence_mp3(duration_ms: int, out_path: Path):\n",
    "    \"\"\"\n",
    "    Creates a silent MP3 using ffmpeg.\n",
    "    \"\"\"\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    seconds = max(duration_ms / 1000.0, 0.01)\n",
    "\n",
    "    run([\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"lavfi\",\n",
    "        \"-i\", f\"anullsrc=r=44100:cl=stereo\",\n",
    "        \"-t\", f\"{seconds:.3f}\",\n",
    "        \"-c:a\", \"libmp3lame\",\n",
    "        \"-q:a\", \"2\",\n",
    "        str(out_path),\n",
    "    ])\n",
    "\n",
    "\n",
    "def concat_mp3_with_reencode(mp3_files: list[Path], out_file: Path):\n",
    "    \"\"\"\n",
    "    Concats MP3s robustly using ffmpeg concat demuxer and re-encodes.\n",
    "    Uses absolute paths to avoid path issues.\n",
    "    \"\"\"\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    list_file = out_file.parent / \"concat_list.txt\"\n",
    "\n",
    "    for p in mp3_files:\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"Missing file: {p}\")\n",
    "\n",
    "    def esc(p: Path) -> str:\n",
    "        return p.resolve().as_posix().replace(\"'\", r\"'\\''\")\n",
    "\n",
    "    with open(list_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in mp3_files:\n",
    "            f.write(f\"file '{esc(p)}'\\n\")\n",
    "\n",
    "    run([\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "        \"-i\", str(list_file),\n",
    "        \"-vn\",\n",
    "        \"-c:a\", \"libmp3lame\",\n",
    "        \"-q:a\", \"2\",\n",
    "        \"-ar\", \"44100\",\n",
    "        \"-ac\", \"2\",\n",
    "        str(out_file),\n",
    "    ])\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    if not ffmpeg_available():\n",
    "        raise RuntimeError(\"ffmpeg not found. Install ffmpeg and try again.\")\n",
    "\n",
    "    OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "    SEG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    turns = parse_dialogue(TEST_SCRIPT)\n",
    "    if not turns:\n",
    "        raise RuntimeError(\"No dialogue turns parsed. Check your [HOST]/[COHOST] tags.\")\n",
    "\n",
    "    voice_map = {\"HOST\": HOST_VOICE, \"COHOST\": COHOST_VOICE}\n",
    "\n",
    "    mp3_sequence = []\n",
    "    silence_path = SEG_DIR / f\"pause_{PAUSE_MS_BETWEEN_TURNS}ms.mp3\"\n",
    "    make_silence_mp3(PAUSE_MS_BETWEEN_TURNS, silence_path)\n",
    "\n",
    "    print(f\"Generating {len(turns)} segments with two voices using model={TTS_MODEL}...\")\n",
    "\n",
    "    for i, turn in enumerate(turns, start=1):\n",
    "        speaker = turn[\"speaker\"]\n",
    "        text = turn[\"text\"]\n",
    "\n",
    "        out_mp3 = SEG_DIR / f\"seg_{i:02d}_{speaker.lower()}.mp3\"\n",
    "        tts_segment(text=text, voice=voice_map[speaker], out_path=out_mp3)\n",
    "        mp3_sequence.append(out_mp3)\n",
    "\n",
    "        # Add pacing pause after each turn except the last\n",
    "        if i != len(turns):\n",
    "            mp3_sequence.append(silence_path)\n",
    "\n",
    "        print(f\"  {i:02d}. {speaker} -> {out_mp3.name}\")\n",
    "\n",
    "    print(\"Concatenating into final audio...\")\n",
    "    concat_mp3_with_reencode(mp3_sequence, FINAL_AUDIO)\n",
    "\n",
    "    print(f\"Done: {FINAL_AUDIO}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a87e3ce",
   "metadata": {},
   "source": [
    "## Step 6 – Refactored Modular Pipeline\n",
    "\n",
    "This cell represents a **clean, modular, and reusable version** of the podcast prototype, designed to be flexible and production-ready. It consolidates all previous steps—article fetching, script generation, chunking, TTS, and audio concatenation—into a single callable function.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Flexible Inputs**\n",
    "   - Accepts either pre-fetched article texts (`urls_text`) or a list of URLs to fetch (`fetch_urls`).\n",
    "   - Allows targeting a specific episode length (`minutes`) and adjusting TTS chunk sizes (`max_chars`).\n",
    "   - Supports specifying different TTS models and voices independently from script generation.\n",
    "\n",
    "2. **Script Generation**\n",
    "   - Generates an original podcast script using OpenAI models.\n",
    "   - Emphasizes engaging storytelling, cinematic narration, and lessons from history.\n",
    "   - Handles both the classic “fall of Rome” narrative and user-provided content.\n",
    "\n",
    "3. **Chunking**\n",
    "   - Splits the script into manageable segments for TTS.\n",
    "   - Avoids cutting mid-sentence when possible.\n",
    "   - Ensures each chunk respects model input limits.\n",
    "\n",
    "4. **Text-to-Speech (TTS)**\n",
    "   - Converts each chunk into an MP3 file.\n",
    "   - Supports any OpenAI TTS model and voice combination.\n",
    "   - Stores temporary audio files in a dedicated chunk directory.\n",
    "\n",
    "5. **Audio Concatenation**\n",
    "   - Combines all chunks into a single final episode.\n",
    "   - Uses `ffmpeg` if available, falling back to `pydub` otherwise.\n",
    "   - Produces a smooth, continuous MP3 suitable for podcast publishing.\n",
    "\n",
    "6. **Refactored Pipeline Function**\n",
    "   - `run_pipeline(...)` serves as the **single entry point** for end-to-end processing.\n",
    "   - Returns the generated script, final audio file path, and optional metadata.\n",
    "   - Makes the workflow reusable in notebooks, scripts, or production applications.\n",
    "\n",
    "7. **Example Main**\n",
    "   - Demonstrates running the pipeline with a set of URLs.\n",
    "   - Prints a preview of the generated script and confirms final audio creation.\n",
    "   - Shows backward compatibility with the previous workflow.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this step matters\n",
    "\n",
    "- Provides a **modular interface** that separates configuration, fetching, TTS, and concatenation.\n",
    "- Allows **reuse across multiple projects** without rewriting core logic.\n",
    "- Simplifies experimentation with:\n",
    "  - Different source content\n",
    "  - TTS voices and models\n",
    "  - Episode lengths and chunk sizes\n",
    "- Forms the foundation for a **scalable AI podcast generation system**, capable of both prototyping and production deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfbb4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== GENERATED PODCAST SCRIPT (preview) =====\n",
      "\n",
      "Rome was one of the most advanced civilizations in history. It built mighty cities, wrote laws, and linked distant lands. \"Could the lessons of ancient Rome help us understand the challenges of our own time?\"\n",
      "\n",
      "At its height, Rome spread across Europe, Asia, and Africa. Its strength came from a capable administration, busy cities, and a disciplined army. Diocletian split power; Constantine moved the capital toward the East.\n",
      "\n",
      "Three forces pushed Rome toward collapse. Climate shifts and plagues cut harvests. Invaders and migrations strained defenses and taxes. Political chaos and costly wars weakened leaders, letting rival groups carve kingdoms.\n",
      "\n",
      "Western Rome faded into new kingdoms; the East endured as Byzantium. Yet Rome’s legacy lived on in law, architecture, and literacy, reminding us that decline is a long, uneven process, not a moment.\n",
      "\n",
      "Recap: peak power, slow unraveling, and hard-won lessons. Crises test nations. The fall of Rome invites us to strengthen institutions, stay adaptable, and act for the common good.\n",
      "\n",
      "Done. Final audio file created: podcast_output/podcast_episode_final.mp3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import Any, Optional\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from newspaper import Article\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config (defaults)\n",
    "# -----------------------------\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "OUTPUT_DIR = Path(\"podcast_output\")\n",
    "CHUNKS_DIR = OUTPUT_DIR / \"chunks\"\n",
    "FINAL_AUDIO_DEFAULT = OUTPUT_DIR / \"podcast_episode_final.mp3\"\n",
    "\n",
    "# Keep headroom for TTS limits\n",
    "MAX_CHARS_PER_CHUNK_DEFAULT = 3500\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Fetch + Script generation\n",
    "# -----------------------------\n",
    "def fetch_articles(urls: list[str]) -> list[dict[str, str]]:\n",
    "    articles: list[dict[str, str]] = []\n",
    "    for url in urls:\n",
    "        try:\n",
    "            article = Article(url)\n",
    "            article.download()\n",
    "            article.parse()\n",
    "            articles.append({\"url\": url, \"text\": article.text})\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {url}: {e}\")\n",
    "    return articles\n",
    "\n",
    "\n",
    "def _estimate_words_target(minutes: int, wpm: int = 150) -> int:\n",
    "    return max(1, minutes) * wpm\n",
    "\n",
    "\n",
    "def generate_podcast_script(\n",
    "    articles: list[dict[str, str]],\n",
    "    minutes: int,\n",
    "    model: str = \"gpt-4o-mini\",\n",
    ") -> str:\n",
    "    sources_text = \"\"\n",
    "    for i, a in enumerate(articles, start=1):\n",
    "        sources_text += f\"\\nSOURCE {i} ({a['url']}):\\n{a['text']}\\n\"\n",
    "\n",
    "    # Let the model target duration, but also give a rough words target as guidance.\n",
    "    words_target = _estimate_words_target(minutes)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a podcast scriptwriter and narrator.\n",
    "\n",
    "Task: Using the sources below, write an original podcast script about the fall of the Roman Empire, suitable for a several-minute episode.\n",
    "\n",
    "Write only the spoken narration.\n",
    "Do not include headers, labels, categories, brackets, stage directions, or performance notes of any kind.\n",
    "\n",
    "Use simple, clear English that a general audience can follow. Rephrase ideas fully in your own words; do not copy sentences from the sources.\n",
    "\n",
    "Make the narration engaging and cinematic using spoken language only.\n",
    "Create emphasis and pacing naturally through:\n",
    "\n",
    "Sentence length\n",
    "\n",
    "Paragraph breaks\n",
    "\n",
    "Punctuation such as commas, ellipses, and short sentences\n",
    "\n",
    "Do not describe pauses, voice changes, or cadence explicitly.\n",
    "If it would not be spoken aloud by a human narrator, it must not appear in the text.\n",
    "\n",
    "Focus on the fall of the Roman Empire and its lessons. Emphasize that history often repeats itself, and that understanding Rome’s decline can offer insight into challenges societies face today.\n",
    "\n",
    "Target length: about {minutes} minutes.\n",
    "Aim for roughly {words_target} words (±10%).\n",
    "\n",
    "The script should naturally include:\n",
    "\n",
    "A strong opening hook that presents Rome as one of the most advanced and influential civilizations in history, and introduces the idea that its decline still matters today. Include the reflective question:\n",
    "“Could the lessons of ancient Rome help us understand the challenges of our own time?”\n",
    "\n",
    "Background and context explaining Rome’s peak, its structure, its significance, and key figures or institutions.\n",
    "\n",
    "Three to five main causes and consequences of the fall, explained in a clear, story-driven way.\n",
    "\n",
    "A brief recap summarizing the main ideas.\n",
    "\n",
    "A reflective closing that connects Rome’s story to lessons for the modern world.\n",
    "\n",
    "End result: a smooth, immersive, ready-to-read script designed for a text-to-speech system, where every word is intended to be spoken aloud.\n",
    "Sources:\n",
    "{sources_text}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You write engaging podcast scripts.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    script = response.choices[0].message.content or \"\"\n",
    "    return script.strip()\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Chunking\n",
    "# -----------------------------\n",
    "def normalize_whitespace(text: str) -> str:\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def chunk_text(text: str, max_chars: int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Chunk by paragraphs, then by sentences if needed.\n",
    "    Avoids cutting mid-sentence when possible.\n",
    "    Hard-slices only as a last resort.\n",
    "    \"\"\"\n",
    "    text = normalize_whitespace(text)\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip()]\n",
    "\n",
    "    chunks: list[str] = []\n",
    "    current = \"\"\n",
    "\n",
    "    def flush():\n",
    "        nonlocal current\n",
    "        if current.strip():\n",
    "            chunks.append(current.strip())\n",
    "        current = \"\"\n",
    "\n",
    "    sentence_split = re.compile(r\"(?<=[.!?])\\s+\")\n",
    "\n",
    "    for p in paragraphs:\n",
    "        parts = [p]\n",
    "        if len(p) > max_chars:\n",
    "            parts = sentence_split.split(p)\n",
    "\n",
    "        for part in parts:\n",
    "            part = part.strip()\n",
    "            if not part:\n",
    "                continue\n",
    "\n",
    "            candidate = part if not current else current + \"\\n\\n\" + part\n",
    "\n",
    "            if len(candidate) <= max_chars:\n",
    "                current = candidate\n",
    "            else:\n",
    "                flush()\n",
    "\n",
    "                if len(part) > max_chars:\n",
    "                    for i in range(0, len(part), max_chars):\n",
    "                        piece = part[i : i + max_chars].strip()\n",
    "                        if piece:\n",
    "                            chunks.append(piece)\n",
    "                else:\n",
    "                    current = part\n",
    "\n",
    "    flush()\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# TTS\n",
    "# -----------------------------\n",
    "def tts_to_mp3(text: str, out_path: Path, tts_model: str, tts_voice: str):\n",
    "    speech = client.audio.speech.create(\n",
    "        model=tts_model,\n",
    "        voice=tts_voice,\n",
    "        input=text,\n",
    "    )\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        f.write(speech.read())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Audio concat (absolute paths)\n",
    "# -----------------------------\n",
    "def ffmpeg_available() -> bool:\n",
    "    return shutil.which(\"ffmpeg\") is not None\n",
    "\n",
    "\n",
    "def _ffmpeg_concat_escape(path: Path) -> str:\n",
    "    p = path.resolve().as_posix()\n",
    "    return p.replace(\"'\", r\"'\\''\")\n",
    "\n",
    "\n",
    "def concat_mp3_ffmpeg(mp3_files: list[Path], out_file: Path):\n",
    "    \"\"\"\n",
    "    Robust concat:\n",
    "      1) Try stream-copy concat (fast, may fail for MP3 chunks).\n",
    "      2) Retry with re-encode (reliable).\n",
    "    Uses absolute paths in concat_list to avoid path duplication issues.\n",
    "    \"\"\"\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    list_file = out_file.parent / \"concat_list.txt\"\n",
    "\n",
    "    missing = [p for p in mp3_files if not p.exists()]\n",
    "    if missing:\n",
    "        raise FileNotFoundError(f\"Missing chunk files: {missing}\")\n",
    "\n",
    "    with open(list_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for p in mp3_files:\n",
    "            f.write(f\"file '{_ffmpeg_concat_escape(p)}'\\n\")\n",
    "\n",
    "    def run(cmd: list[str]):\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if res.returncode != 0:\n",
    "            raise RuntimeError(\n",
    "                \"ffmpeg concat failed.\\n\"\n",
    "                f\"CMD: {' '.join(cmd)}\\n\\n\"\n",
    "                f\"STDOUT:\\n{res.stdout}\\n\\nSTDERR:\\n{res.stderr}\"\n",
    "            )\n",
    "        return res\n",
    "\n",
    "    try:\n",
    "        run([\n",
    "            \"ffmpeg\", \"-y\",\n",
    "            \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "            \"-i\", str(list_file),\n",
    "            \"-c\", \"copy\",\n",
    "            str(out_file),\n",
    "        ])\n",
    "        return\n",
    "    except RuntimeError as e:\n",
    "        print(str(e))\n",
    "        print(\"\\nRetrying with re-encode (more reliable)...\\n\")\n",
    "\n",
    "    run([\n",
    "        \"ffmpeg\", \"-y\",\n",
    "        \"-f\", \"concat\", \"-safe\", \"0\",\n",
    "        \"-i\", str(list_file),\n",
    "        \"-vn\",\n",
    "        \"-c:a\", \"libmp3lame\",\n",
    "        \"-q:a\", \"2\",\n",
    "        \"-ar\", \"44100\",\n",
    "        \"-ac\", \"2\",\n",
    "        str(out_file),\n",
    "    ])\n",
    "\n",
    "\n",
    "def concat_mp3_pydub(mp3_files: list[Path], out_file: Path):\n",
    "    from pydub import AudioSegment  # pip install pydub\n",
    "\n",
    "    combined = AudioSegment.empty()\n",
    "    for p in mp3_files:\n",
    "        combined += AudioSegment.from_file(p, format=\"mp3\")\n",
    "\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    combined.export(out_file, format=\"mp3\")\n",
    "\n",
    "\n",
    "def concat_mp3(mp3_files: list[Path], out_file: Path):\n",
    "    if ffmpeg_available():\n",
    "        concat_mp3_ffmpeg(mp3_files, out_file)\n",
    "    else:\n",
    "        print(\"ffmpeg not found in PATH. Trying pydub fallback...\")\n",
    "        concat_mp3_pydub(mp3_files, out_file)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Refactored pipeline entrypoint\n",
    "# -----------------------------\n",
    "def run_pipeline(\n",
    "    urls_text: list[str],\n",
    "    minutes: int,\n",
    "    tts_model: str,\n",
    "    tts_voice: str,\n",
    "    max_chars: int,\n",
    "    *,\n",
    "    output_dir: Path = OUTPUT_DIR,\n",
    "    chunks_dir: Optional[Path] = None,\n",
    "    final_audio_path: Optional[Path] = None,\n",
    "    fetch_urls: Optional[list[str]] = None,\n",
    "    script_model: str = \"gpt-5-nano\",\n",
    ") -> tuple[str, Path, Any]:\n",
    "    \"\"\"\n",
    "    Call signature the user asked for:\n",
    "        script, final_audio_path, _ = run_pipeline(urls_text, minutes, tts_model, tts_voice, max_chars)\n",
    "\n",
    "    Inputs:\n",
    "      - urls_text: list[str] of source article texts already fetched (strings).\n",
    "                  If you want the function to fetch itself, pass fetch_urls=[...]\n",
    "                  and urls_text can be [].\n",
    "      - minutes: target episode length\n",
    "      - tts_model / tts_voice: passed to OpenAI audio.speech.create(...)\n",
    "      - max_chars: chunk size for TTS\n",
    "\n",
    "    Returns:\n",
    "      - script (str)\n",
    "      - final_audio_path (Path)\n",
    "      - metadata (Any): currently None, reserved for future use\n",
    "    \"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    chunks_dir = chunks_dir or (output_dir / \"chunks\")\n",
    "    chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    final_audio_path = final_audio_path or (output_dir / \"podcast_episode_final.mp3\")\n",
    "\n",
    "    # 1) Sources: either use provided texts or fetch from URLs\n",
    "    articles: list[dict[str, str]] = []\n",
    "    if fetch_urls:\n",
    "        fetched = fetch_articles(fetch_urls)\n",
    "        if not fetched:\n",
    "            raise RuntimeError(\"No articles fetched. Check URLs / connectivity.\")\n",
    "        articles = fetched\n",
    "    else:\n",
    "        if not urls_text:\n",
    "            raise ValueError(\"urls_text is empty. Provide texts or pass fetch_urls=[...] to fetch.\")\n",
    "        # Preserve the original script generator interface by faking URLs.\n",
    "        articles = [{\"url\": f\"provided_text_{i+1}\", \"text\": t} for i, t in enumerate(urls_text)]\n",
    "\n",
    "    # 2) Script\n",
    "    script = generate_podcast_script(articles, minutes=minutes, model=script_model)\n",
    "\n",
    "    # 3) Chunk\n",
    "    chunks = chunk_text(script, max_chars=max_chars)\n",
    "\n",
    "    # 4) TTS each chunk\n",
    "    mp3_files: list[Path] = []\n",
    "    for idx, chunk in enumerate(chunks, start=1):\n",
    "        mp3_path = chunks_dir / f\"chunk_{idx:02d}.mp3\"\n",
    "        tts_to_mp3(chunk, mp3_path, tts_model=tts_model, tts_voice=tts_voice)\n",
    "        mp3_files.append(mp3_path)\n",
    "\n",
    "    # 5) Concat\n",
    "    concat_mp3(mp3_files, final_audio_path)\n",
    "\n",
    "    return script, final_audio_path, None\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Example old-style main (optional)\n",
    "# -----------------------------\n",
    "def main():\n",
    "    urls = [\n",
    "        \"https://www.nationalgeographic.com/history/article/fall-of-ancient-roman-empire\",\n",
    "        \"https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml\",\n",
    "        \"https://www.britannica.com/place/Roman-Empire/Height-and-decline-of-imperial-Rome\",\n",
    "        \"https://en.wikipedia.org/wiki/Fall_of_the_Western_Roman_Empire\",\n",
    "    ]\n",
    "\n",
    "    # Old flow: fetch URLs, then run_pipeline via fetch_urls\n",
    "    script, final_audio_path, _ = run_pipeline(\n",
    "        urls_text=[],\n",
    "        minutes=1,\n",
    "        tts_model=\"tts-1\",\n",
    "        tts_voice=\"sage\",\n",
    "        max_chars=MAX_CHARS_PER_CHUNK_DEFAULT,\n",
    "        fetch_urls=urls,\n",
    "    )\n",
    "\n",
    "    print(\"\\n===== GENERATED PODCAST SCRIPT (preview) =====\\n\")\n",
    "    print(script[:2000] + (\"\\n...\\n\" if len(script) > 2000 else \"\"))\n",
    "    print(f\"\\nDone. Final audio file created: {final_audio_path.as_posix()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5912124d",
   "metadata": {},
   "source": [
    "## Step 7 – Gradio User Interface for Podcast Generation\n",
    "\n",
    "This cell wraps the full pipeline in a **web-based interface** using Gradio, allowing users to generate podcast episodes without touching the code.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Input Configuration**\n",
    "   - **Article URLs**: Users paste one URL per line to serve as sources.\n",
    "   - **Target Length**: Specify the desired episode duration in minutes.\n",
    "   - **TTS Model and Voice**: Choose which text-to-speech model and voice to use.\n",
    "   - **Chunk Size**: Adjust how the script is split into chunks for TTS.\n",
    "\n",
    "2. **Outputs**\n",
    "   - **Script Preview**: Displays the generated podcast script in a textbox.\n",
    "   - **Audio Player**: Provides a playable MP3 of the final episode.\n",
    "\n",
    "3. **Controls**\n",
    "   - **Generate Episode**: Calls the `run_pipeline` function with the provided inputs, generating both the script and audio.\n",
    "   - **Clear**: Resets the script and audio output.\n",
    "\n",
    "4. **UI Layout and Styling**\n",
    "   - Responsive design with a sidebar for configuration and a main panel for outputs.\n",
    "   - Custom CSS to improve readability, spacing, and responsive behavior.\n",
    "   - Two-column layout: narrow left column for settings, wider right column for outputs.\n",
    "\n",
    "5. **Integration with Pipeline**\n",
    "   - Uses `roman_run` as the callback function, which internally calls `run_pipeline` (Step 6).\n",
    "   - Ensures OpenAI API key is set before running.\n",
    "   - Returns both the generated script and the path to the final audio file.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this step matters\n",
    "\n",
    "- Provides a **friendly, interactive interface** for non-technical users to generate AI-powered podcast episodes.\n",
    "- Makes the workflow **accessible in a browser**, so the system can be demonstrated or shared without installing Python.\n",
    "- Complements the modular pipeline by exposing all key parameters (sources, length, TTS model, voice, chunk size) in one place.\n",
    "- Enables quick experimentation with different source articles, episode lengths, and voices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7c6abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elsa/miniconda3/envs/py311env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/var/folders/m9/k3904p616cvg53z97mbf8sfc0000gn/T/ipykernel_51946/843055933.py:73: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme, css. Please pass these parameters to launch() instead.\n",
      "  with gr.Blocks(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "\n",
    "DEFAULT_URLS_TEXT = \"\\n\".join([\n",
    "   \"https://www.nationalgeographic.com/history/article/fall-of-ancient-roman-empire\",\n",
    "        \"https://www.bbc.co.uk/history/ancient/romans/fallofrome_article_01.shtml\",\n",
    "        #\"https://www.britannica.com/place/Roman-Empire/Height-and-decline-of-imperial-Rome\",\n",
    "        #\"https://en.wikipedia.org/wiki/Fall_of_the_Western_Roman_Empire\",\n",
    "])\n",
    "\n",
    "APP_CSS = \"\"\"\n",
    "#app {\n",
    "  max-width: 1100px;\n",
    "  margin: 0 auto;\n",
    "  padding: 32px 24px;\n",
    "}\n",
    "\n",
    ".section {\n",
    "  margin-top: 20px;\n",
    "}\n",
    "\n",
    ".sidebar .section:first-child {\n",
    "  margin-top: 0px;\n",
    "}\n",
    "\n",
    ".primary-action button {\n",
    "  min-height: 44px;\n",
    "  font-weight: 600;\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    ".secondary-action button {\n",
    "  background: transparent !important;\n",
    "  border: 1px solid #E5E7EB !important;\n",
    "  color: #374151 !important;\n",
    "  width: 100%;\n",
    "  min-height: 44px;\n",
    "}\n",
    "\n",
    "/* Output emphasis */\n",
    "#script_out textarea {\n",
    "  line-height: 1.6 !important;\n",
    "  font-size: 14.5px !important;\n",
    "}\n",
    "\n",
    "/* Make audio span full width comfortably */\n",
    "#audio_out {\n",
    "  width: 100%;\n",
    "}\n",
    "\n",
    "/* Slightly tighten the left column controls */\n",
    ".sidebar label, .sidebar .gr-label {\n",
    "  margin-bottom: 6px !important;\n",
    "}\n",
    "\n",
    "/* Responsive: stack on small screens */\n",
    "@media (max-width: 900px) {\n",
    "  #main_row {\n",
    "    flex-direction: column !important;\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def roman_run(urls_text: str, minutes: int, tts_model: str, tts_voice: str, max_chars: int):\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise gr.Error(\"OPENAI_API_KEY not found.\")\n",
    "    script, final_audio_path, _ = run_pipeline(\n",
    "        urls_text, minutes, tts_model, tts_voice, max_chars\n",
    "    )\n",
    "    return script, final_audio_path\n",
    "\n",
    "\n",
    "with gr.Blocks(\n",
    "    theme=gr.themes.Soft(),\n",
    "    css=APP_CSS,\n",
    "    title=\"Fall of Rome Podcast Generator\"\n",
    ") as demo:\n",
    "\n",
    "    with gr.Column(elem_id=\"app\"):\n",
    "\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            # Fall of Rome Podcast Generator\n",
    "            Paste article URLs, choose a target length, and generate a narrated podcast episode.\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        with gr.Row(elem_id=\"main_row\", elem_classes=[\"section\"]):\n",
    "            # LEFT: Configuration (narrower)\n",
    "            with gr.Column(scale=4, elem_classes=[\"sidebar\"]):\n",
    "                with gr.Column(elem_classes=[\"section\"]):\n",
    "                    gr.Markdown(\"## Sources\")\n",
    "                    urls_text = gr.Textbox(\n",
    "                        label=\"Article URLs (one per line)\",\n",
    "                        value=DEFAULT_URLS_TEXT,\n",
    "                        lines=3,\n",
    "                        placeholder=\"Paste one URL per line...\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(elem_classes=[\"section\"]):\n",
    "                    gr.Markdown(\"## Settings\")\n",
    "                    minutes = gr.Number(\n",
    "                        label=\"Target length (minutes)\",\n",
    "                        value=10,\n",
    "                        precision=0,\n",
    "                        minimum=1,\n",
    "                        maximum=20\n",
    "                    )\n",
    "                    tts_model = gr.Textbox(label=\"TTS model\", value=\"tts-1\")\n",
    "                    tts_voice = gr.Dropdown(\n",
    "                        label=\"Voice\",\n",
    "                        choices=[\"alloy\", \"onyx\", \"nova\", \"shimmer\", \"echo\", \"fable\", \"ash\", \"sage\", \"coral\"],\n",
    "                        value=\"onyx\"\n",
    "                    )\n",
    "                    max_chars = gr.Slider(\n",
    "                        label=\"Chunk size (characters)\",\n",
    "                        minimum=1200,\n",
    "                        maximum=4500,\n",
    "                        step=100,\n",
    "                        value=3500\n",
    "                    )\n",
    "\n",
    "                with gr.Row(elem_classes=[\"section\"]):\n",
    "                    with gr.Column(scale=1, elem_classes=[\"primary-action\"]):\n",
    "                        generate_btn = gr.Button(\"Generate episode\", variant=\"primary\")\n",
    "                    with gr.Column(scale=1, elem_classes=[\"secondary-action\"]):\n",
    "                        clear_btn = gr.Button(\"Clear\")\n",
    "\n",
    "            # RIGHT: Outputs (wider)\n",
    "            with gr.Column(scale=7):\n",
    "                with gr.Column(elem_classes=[\"section\"]):\n",
    "                    gr.Markdown(\"## Script\")\n",
    "                    script_out = gr.Textbox(\n",
    "                        elem_id=\"script_out\",\n",
    "                        lines=7,\n",
    "                        placeholder=\"Generated script will appear here…\"\n",
    "                    )\n",
    "\n",
    "                with gr.Column(elem_classes=[\"section\"]):\n",
    "                    gr.Markdown(\"## Audio\")\n",
    "                    audio_out = gr.Audio(\n",
    "                        elem_id=\"audio_out\",\n",
    "                        type=\"filepath\"\n",
    "                    )\n",
    "\n",
    "        generate_btn.click(\n",
    "            fn=roman_run,\n",
    "            inputs=[urls_text, minutes, tts_model, tts_voice, max_chars],\n",
    "            outputs=[script_out, audio_out]\n",
    "        )\n",
    "\n",
    "        clear_btn.click(\n",
    "            fn=lambda: (\"\", None),\n",
    "            outputs=[script_out, audio_out]\n",
    "        )\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
