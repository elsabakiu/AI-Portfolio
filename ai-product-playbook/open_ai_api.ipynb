{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# OpenAI API Examples\n",
        "\n",
        "This notebook demonstrates various OpenAI API usage patterns including responses and chat completions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install openai pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from typing import List\n",
        "\n",
        "# Initialize client\n",
        "client = OpenAI(api_key='your_openai_api_key_here')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using client.responses.create\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Simple Client with Non-Reasoning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"What is machine learning?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Client with Reasoning Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"o3-mini\",\n",
        "    input=\"Solve this step by step: If a train travels 120 km in 2 hours, how long will it take to travel 300 km?\"\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image as Input\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"text\",\n",
        "                    \"text\": \"What's in this image?\"\n",
        "                },\n",
        "                {\n",
        "                    \"type\": \"image_url\",\n",
        "                    \"image_url\": {\n",
        "                        \"url\": \"https://upload.wikimedia.org/wikipedia/commons/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
        "                    }\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Temperature, Model, Instructions (Non-Reasoning)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"Write a creative story about AI\",\n",
        "    instructions=\"You are a creative writing assistant. Write in a poetic style.\",\n",
        "    temperature=0.9\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Responses with Reasoning Effort\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    instructions=\"Talk like a pirate.\",\n",
        "    input=\"Are semicolons optional in JavaScript?\",\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Alternative Response Formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Talk like a pirate.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verbosity Parameter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    input=\"What is the answer to the ultimate question of life, the universe, and everything?\",\n",
        "    text={\n",
        "        \"verbosity\": \"low\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5.2\",\n",
        "    input=\"What is the answer to the ultimate question of life, the universe, and everything?\",\n",
        "    text={\n",
        "        \"verbosity\": \"high\"\n",
        "    }\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiple Turns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response1 = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"My name is Alice\"\n",
        ")\n",
        "\n",
        "print(\"Turn 1:\", response1.output_text)\n",
        "\n",
        "response2 = client.responses.create(\n",
        "    model=\"gpt-4o\",\n",
        "    input=\"What's my name?\",\n",
        "    previous_response_id=response1.id\n",
        ")\n",
        "\n",
        "print(\"\\nTurn 2:\", response2.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Roles (Developer, User, Assistant)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-5\",\n",
        "    reasoning={\"effort\": \"low\"},\n",
        "    input=[\n",
        "        {\n",
        "            \"role\": \"developer\",\n",
        "            \"content\": \"Talk like a pirate.\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Are semicolons optional in JavaScript?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.output_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using client.chat.completions.create\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Basic Messages Array\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Explain neural networks in one sentence.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Structured Output with Pydantic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class CalendarEvent(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    participants: list[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n",
        "    ],\n",
        "    response_format=CalendarEvent,\n",
        ")\n",
        "\n",
        "event = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Research Paper Extraction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class ResearchPaperExtraction(BaseModel):\n",
        "    title: str\n",
        "    authors: list[str]\n",
        "    abstract: str\n",
        "    keywords: list[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert at structured data extraction. You will be given unstructured text from a research paper and should convert it into the given structure.\"},\n",
        "        {\"role\": \"user\", \"content\": \"...\"}\n",
        "    ],\n",
        "    response_format=ResearchPaperExtraction,\n",
        ")\n",
        "\n",
        "research_paper = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "research_paper \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Moderation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from typing import Optional\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Category(str, Enum):\n",
        "    violence = \"violence\"\n",
        "    sexual = \"sexual\"\n",
        "    self_harm = \"self_harm\"\n",
        "\n",
        "class ContentCompliance(BaseModel):\n",
        "    is_violating: bool\n",
        "    category: Optional[Category]\n",
        "    explanation_if_violating: Optional[str]\n",
        "\n",
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Determine if the user input violates specific guidelines and explain if they do.\"},\n",
        "        {\"role\": \"user\", \"content\": \"How do I prepare for a job interview?\"}\n",
        "    ],\n",
        "    response_format=ContentCompliance,\n",
        ")\n",
        "\n",
        "compliance = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compliance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "completion = client.chat.completions.parse(\n",
        "    model=\"gpt-4o-2024-08-06\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Determine if the user input violates specific guidelines and explain if they do.\"},\n",
        "        {\"role\": \"user\", \"content\": \"I want to hurt myself.\"}\n",
        "    ],\n",
        "    response_format=ContentCompliance,\n",
        ")\n",
        "\n",
        "compliance = completion.choices[0].message.parsed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "compliance"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "consulting",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}